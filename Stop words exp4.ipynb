{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#*Removal* of stop words using NLTK\n",
        "\n"
      ],
      "metadata": {
        "id": "tZsIgvKVSFRy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXP: 4"
      ],
      "metadata": {
        "id": "Y1nLDr5KV4qm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###First applying this method with the text file to analyze the large size of the file like text doc.\n",
        "###Here, i've applied this method on my research paper data for the further analysis we can also increase the size of the file."
      ],
      "metadata": {
        "id": "ukZSMwfD5koc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "#declaring the function to remove stop wordsn for example: is, am and many more\n",
        "def remove_stopwords(words):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    return filtered_words\n",
        "\n",
        "#declaring the funcition to read text from a text.txt file\n",
        "def read_text(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "#defining Main function\n",
        "def main():\n",
        "    #text from file\n",
        "    filename = 'text.txt'  # Change to the name of your .txt file\n",
        "    text = read_text(filename)\n",
        "\n",
        "    #tokenize the text into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    #tokenize each sentence into words,\n",
        "    #remove stop words, and then rejoining into sentences\n",
        "    cleaned_sentences = []\n",
        "    for sentence in sentences:\n",
        "        words = word_tokenize(sentence)\n",
        "        cleaned_words = remove_stopwords(words)\n",
        "        cleaned_sentence = ' '.join(cleaned_words)\n",
        "        cleaned_sentences.append(cleaned_sentence)\n",
        "\n",
        "    #Result\n",
        "    print(\"Cleaned sentences:\")\n",
        "    for sentence in cleaned_sentences:\n",
        "        print(sentence)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqBdgSt63r2O",
        "outputId": "f8969268-1aac-43b0-c82e-1a9aa2f50e66"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned sentences:\n",
            "Reliable pose estimation uncooperative satellites key technology enabling future on-orbit servicing debris removal missions .\n",
            "Kelvins Satellite Pose Estimation Challenge aims evaluating comparing monocular vision\u0002based approaches pushing state-of-the-art prob\u0002lem .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing stopword method on sentences\n",
        "Basicaly it's for the small size of the text data."
      ],
      "metadata": {
        "id": "cG_xvIiB6Qte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "#NLTK stopwords data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "text = \"Natural language processing is a machine learning technology\"\n",
        "\n",
        "#tokenize the text into words\n",
        "words = word_tokenize(text)\n",
        "\n",
        "#Remove stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "# Print the filtered words\n",
        "print(\"Original text:\", text)\n",
        "print(\"\\nFiltered words:\")\n",
        "print(filtered_words)\n",
        "\n",
        "#result\n",
        "#is, a both are removed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jHMK5ebRQq9",
        "outputId": "c70d2514-f4ed-4d09-807a-323a5a8c0611"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: Natural language processing is a machine learning technology\n",
            "\n",
            "Filtered words:\n",
            "['Natural', 'language', 'processing', 'machine', 'learning', 'technology']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}